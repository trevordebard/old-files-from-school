tdebar2
CSC 1351
Project 3

RANDOM ORDER: Under random conditions, Selection Sort preformed worse, followed by Insertion Sort. Quick and Merge Sort were more or less the same, but Quick Sort did preform better. It was expected for Selection Sort to preform poorly in these conditions, as it goes over the same steps regardless of the order of data; therefore its Big-O value is always O(n^2). The average Big O of insertion sort is O(n^2), and this was consistent in its run in this case. Quick Sort and Merge sort preformed more or less the same. Merge sort always has a time complexity of O(n log (n), and the average case of Quick Sort is also O(n log(n)), which was exemplified with random data.

ASCENDING ORDER: When the data is was sorted in ascending order, Insertion and Merge Sort preformed significantly better than Quick Sort and Selection Sort. This is expected, as the best case scenario for insertion sort is when data is already sorted because it uses the least amount of comparisons, causing a Big-O value of O(n). Merge Sort also preformed very well with a Big-O value of O(n log(n)). Selection and Quick Sort are more or less the same. Each formed a parabolic line when graphed, which is expected because the worst case Big-O values for each sorting method is O(n^2). Selection sort must go through the same steps no matter the initial sorting of the data, therefore it always has a parabolic graph; this test helps demonstrate that.  Ascending order is the worst case scenario for quick sort because when the array is in ascending order initially, every time you partition, you have at least 1 element. That is why it is also graphed parabolically. 

DESCENDING ORDER: When the data was sorted in descending order, Section Sort and Quick Sort preformed worst, with Insertion following close behind. The Big-O value of all three was O(n^2). Insertion sort’s worst case scenario is descending order because it requires the most amount of comparisons. Selection sort is always parabolic because it requires the same steps no matter how the data is already sorted. Quick Sort is O(n^2) when the array is in descending order as well because there is always one element left whenever you partition. Merge Sort preformed best with descending order with a Big-O value of O(n log(n)). 

Overall, it is clear the Merge Sort is a great sorting algorithm in most real word cases, as it never preforms poorly and always has a time complexity of O(n log (n)). That being said, quick sort does very well in it’s average case (when data is in random order), and could be useful to use over Merge Sort in many instances because Quick Sort happens in place and is therefore better for memory. In instances when you have data already in ascending order, it is better to use insertion sort. Of the four algorithms tested, Selection Sort seems to be the worst. It always preformed poorly and does not have a varying time complexity. The only benefit that I can see is that you will never have doubts as to how long data will be sorted because it will always be O(n^2). All of these results support the theoretical time complexities taught in class and in our book.

